[
{
	"uri": "https://unrealgt.github.io/basics/indroduction/",
	"title": "Indroduction",
	"tags": [],
	"description": "",
	"content": "UnrealGT is a tool that can generate data from a virtual scene inside the Unreal Engine. The goal is to provide to provide a Toolkit that is as flexible as possible, with many data generation scenarios supported out of the box and the ability to easily extend the built in components for more complex scenarios. To achive this goal this tool is directly integrated into the Engine\u0026rsquo;s editor in the form of a plugin and therfore requires some basic knowldege about the unreal engine.\nIf you are looking for a more high level solution you can check out the following projects:\nCARLA and AirSim are great tools for the simulation autonomous vehicles. Both rely on the unreal engine to provide data from the virtual scene, which is then used to issue commands to the vehicle inside the scene.\nUnrealCV provides a provides a python client that lets you extract a lot of scene data from an unreal scene via a vareiety of commands.\n"
},
{
	"uri": "https://unrealgt.github.io/components/generator/image/",
	"title": "Image",
	"tags": [],
	"description": "",
	"content": "GTImageGeneratorComponent  \rA virtual camera that enerates RGB images. A lot of camera specific paramters like exposure, ISO, shutterspeed, bloom, fov (focal-length) can be configured. These parameters can be found in the Image, PostProcessVolume and Projection Categories.\nFor maximum compatibility the generated images are encoded in a standardized format currently BMP and PNG are supported.\nIt is also possible to randomize resolution and gamma, which can bes useful for traning data, more ranomizable properties will be added in the future.\rProperties\rImage\rbool  bUseRandomGamma\rIf enabled will choose a random gamma between TargetGamma and TargetGammaMax for each captured image. This is useful for generating Training data.\r\rFIntPoint  Resolution\rThe resolution the generated images will have.\r\rbool  bRandomResolution\rIf enabled will choose a random resolution between Resolution and ResolutionMax for each captured image. This is useful for generating Training data.\r\rFIntPoint  ResolutionMax\rThe maximum Resolution to use if bRandomResolution is enabled.\r\rfloat  TargetGammaMax\rThe maximum gamma to use if bRandomResolution is enabled.\r\rbool  bAntiAliasing\rPerform anti aliasing when an image is rendered. Highly recommended for basic images, but might cause issues if used with segmentation or depth generators. Temporal Anti-Aliasing might cause \u0026ldquo;jittering\u0026rdquo; if the generator is not moving.\r\rbool  bUseDisplayGamma\rA virtual camera that enerates RGB images. A lot of camera specific paramters like exposure, ISO, shutterspeed, bloom, fov (focal-length) can be configured. These parameters can be found in the Image, PostProcessVolume and Projection Categories.\nFor maximum compatibility the generated images are encoded in a standardized format currently BMP and PNG are supported.\nIt is also possible to randomize resolution and gamma, which can bes useful for traning data, more ranomizable properties will be added in the future.\r\rfloat  TargetGamma\rSpecify a custom gama value for images.\r\rEGTImageFileFormat  ImageFormat\rThe format the image will have, currently only .bmp and .png are supported.\r\rPostProcessVolume\rFPostProcessSettings  PostProcessSettings\rPost-process settings to use FPostProcessSettings\r\rProjection\rfloat  FOVAngle\rCamera field of view (in degrees).\r\rTEnumAsByte\u0026lt;ECameraProjectionMode::Type\u0026gt;  ProjectionType\rCamera projection type.\r\rfloat  OrthoWidth\rThe desired width (in world units) of the orthographic view (ignored in Perspective mode)\r\rSceneCapture\rbool  bEnableClipPlane\rEnables a clip plane while rendering the scene capture which is useful for portals. The global clip plane must be enabled in the renderer project settings for this to work.\r\rFVector  ClipPlaneBase\rBase position for the clip plane, can be any position on the plane.\r\rFVector  ClipPlaneNormal\rNormal for the plane.\r\r"
},
{
	"uri": "https://unrealgt.github.io/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": "Chapter 1 Basics The plugin adds components that allow you to extract data from an level inside the Unreal Engine. This chapter will guide you through the installation process for the plugin and features a basic example.\nThis guide assumes that you have basic knowledge of the Unreal Engine. If this is not the case head over to UE\u0026rsquo;s documentation first.\n"
},
{
	"uri": "https://unrealgt.github.io/components/generator/depth/",
	"title": "Depth",
	"tags": [],
	"description": "",
	"content": "GTDepthImageGeneratorComponent  \rGenerates depth images. Uses planar depth as default setting, perspective depth can be enabled via bUsePerspectiveDepth.\nThe depth is encoded in millimeters (mm) in the RGB channels of the image. This means the depth value is a 24bit with a maximum value of 16.777216 km. (TODO add nanometer option). The RGB values can be converted to mm using the following formula: R + G * 256 + B * 256 * 256. See https://github.com/unrealgt/unrealgt/blob/master/Examples/PythonDepthConvert/main.py for an example. Note: Anti-Aliasing is disabled for depth generators by default!\rProperties\rDepth\rbool  bUsePerspectiveDepth\rGenerates depth images. Uses planar depth as default setting, perspective depth can be enabled via bUsePerspectiveDepth.\nThe depth is encoded in millimeters (mm) in the RGB channels of the image. This means the depth value is a 24bit with a maximum value of 16.777216 km. (TODO add nanometer option). The RGB values can be converted to mm using the following formula: R + G * 256 + B * 256 * 256. See https://github.com/unrealgt/unrealgt/blob/master/Examples/PythonDepthConvert/main.py for an example. Note: Anti-Aliasing is disabled for depth generators by default!\r\rfloat  MaxZ\rMaximum depth(distance) to record.\r\rImage\rbool  bRandomResolution\rIf enabled will choose a random resolution between Resolution and ResolutionMax for each captured image. This is useful for generating Training data.\r\rFIntPoint  ResolutionMax\rThe maximum Resolution to use if bRandomResolution is enabled.\r\rbool  bAntiAliasing\rPerform anti aliasing when an image is rendered. Highly recommended for basic images, but might cause issues if used with segmentation or depth generators. Temporal Anti-Aliasing might cause \u0026ldquo;jittering\u0026rdquo; if the generator is not moving.\r\rEGTImageFileFormat  ImageFormat\rThe format the image will have, currently only .bmp and .png are supported.\r\rFIntPoint  Resolution\rThe resolution the generated images will have.\r\rProjection\rfloat  FOVAngle\rCamera field of view (in degrees).\r\r"
},
{
	"uri": "https://unrealgt.github.io/components/generator/",
	"title": "Generator",
	"tags": [],
	"description": "",
	"content": "Chapter 2.1 Generators TODO explain data generators in depth\nAvailable Generators \rImage\r\r\rDepth\r\r\rNormal\r\r\rSegmentation\r\r\rActorInfo\r\r\rCalibration\r\r\r"
},
{
	"uri": "https://unrealgt.github.io/components/",
	"title": "Components",
	"tags": [],
	"description": "",
	"content": "Chapter 2 Generators, Streamers \u0026amp; Triggers The data generation process is split into 3 different component types. These components can be combined to create complex data generation constructs.\nThe basic generation workflow will look like this: Trigger -\u0026gt; Generator -\u0026gt; Streamer\nTirggers are used to kick of the generation, a trigger can be time based or based on an event (a motion sensor for example).\nGenerators are resposible for data collection from the scene.\nStreamers can than be used to transport the collected data from the engine to an external storage or API (e.g. the File System).\n"
},
{
	"uri": "https://unrealgt.github.io/basics/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "Requirements  Unreal Engine 4.21 or higher  Windows  Visual Studio 2017 or 2019 (2015 should work aswell but is not tested)  macOS  XCode Command Line Tools  Linux  Nothing if you already built the engine from source  Installation The only way to install the plugin is to build it from Source in an existing project. This requires you to build your project from source manually.\n  Clone this repository into your projects plugin Directory.\n  Generate the project files (Cmake, Visual Studio Solution, Vscode workspace\u0026hellip;) files by right clicking your projects .uproject file on Windows/macOS or by with GenerateProjectFiles.sh on linux.\n  Build \u0026amp; Run the generated solution/cmake project from your IDE or the CLI.\nSelect DebugGameEditor or DevelopmentGameEditor as Target.\n  After the Editor has launched goto Edit \u0026gt; Plugins and enable the UnrealGT plugin.\n  "
},
{
	"uri": "https://unrealgt.github.io/components/generator/normal/",
	"title": "Normal",
	"tags": [],
	"description": "",
	"content": "GTImageNormalGeneratorComponent  \rRenders the surface normals of the objects in the scene. The normals are encoded in the RGB channels. They can be converted from RGB to world space coordinates using: RGB -\u0026gt; Normal: 2 * C/255 C - 1 Note: Anti-Aliasing is disabled for normal generators by default!\rProperties\rImage\rEGTImageFileFormat  ImageFormat\rThe format the image will have, currently only .bmp and .png are supported.\r\rFIntPoint  Resolution\rThe resolution the generated images will have.\r\rbool  bRandomResolution\rIf enabled will choose a random resolution between Resolution and ResolutionMax for each captured image. This is useful for generating Training data.\r\rFIntPoint  ResolutionMax\rThe maximum Resolution to use if bRandomResolution is enabled.\r\rbool  bAntiAliasing\rPerform anti aliasing when an image is rendered. Highly recommended for basic images, but might cause issues if used with segmentation or depth generators. Temporal Anti-Aliasing might cause \u0026ldquo;jittering\u0026rdquo; if the generator is not moving.\r\rProjection\rfloat  FOVAngle\rCamera field of view (in degrees).\r\r"
},
{
	"uri": "https://unrealgt.github.io/components/streamer/",
	"title": "Streamer",
	"tags": [],
	"description": "",
	"content": "Chapter 2.2 Streamers TODO explain data streamers in depth\nAvailable Streamers \rHttp\r\r\rTcp\r\r\rFile\r\r\r"
},
{
	"uri": "https://unrealgt.github.io/advanced_examples/",
	"title": "Advanced Examples",
	"tags": [],
	"description": "",
	"content": "Chapter 3 Advanced Examples Examples that show of the complete process from data generation with UnrealGT to the processing with a thridparty tool.\n"
},
{
	"uri": "https://unrealgt.github.io/basics/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "The Plugin exposes a vereity of actor components, which can be used to generate data from the virtual world inside the Editor. The following will explain how to capture images data from within level.\nFirst open a level of your choice inside the unreal Editor.\n After that right click in the content browser to create a new Blueprint and choose Actor as base class.\n  Open the created Blueprint in the editor.\n And add the following components to your created Blueprint: ULImageGenerator, ULFileStreamer, ULTimedCaptureTrigger and an optional ULCameraMovement\n  Component Configuration ULImageGenerator\nThe Image generator is responsible for generating pixel data from the scene.\nYou can configure the resolution and output image format. We use BMP as format in this example since it doesn\u0026rsquo;t require CPU heavy compression.\nKeep in mind that multiple image generators or high resolutions will degrade your performance at runtime, because each image generator requires it\u0026rsquo;s own render pass.\n ULFileStreamer\nA Streamer component streams generated Data. In this case the generated image will be streamed into a file.\nTo link the streamer with a generator select the image generator from the dropdown.\nDue to a limitation the dropdown will only list components after the blueprint was compiled, so if your ImageGenerator doesn\u0026rsquo;t show up at first hit compile at the top and retry.\n You can also set the naming convention for the created files. You have access to {ID} and {Time} as variables. The files are stored inside your Projects Saved Directory in the UnrealGT folder.\nULTimedCaptureTrigger\nThis component is responsible for triggering Data generation. Generators that should be triggered by this component, must be added to the Data Generators Array. Here we add our image generator to the Array.\n Generation is triggered at a fixed time interval which can be modified by changing the Frame Rate parameter 1/framerate = time between images in seconds. Be careful with high frame rates as those will heavily degrade performance.\nULCameraMovement (optional)\nIf you don\u0026rsquo;t want to capture at a fixed location you can add a CameraMovementComponent to your blueprint. This component will add some basic movement capabilities to your Blueprint/Actor, which can be configured in the properties tab.\nWe choose the default Follow Main View as movement mode. (TODO movement mode will be an enum in the future update image)\n  Follow Main View will follow your main viewport camera/player Follow Actor will follow a actor, this actor can only be selected after the Blueprint has been placed in a level Follow Rail will follow a camera Rail Actor, you can configure the speed at which our Blueprint Actor will follow the rail.\nTutorial for camera rails: https://docs.unrealengine.com/en-us/Engine/Sequencer/HowTo/CameraRigRail you can skip 2-3. and 9.-16, we will use our blueprint as cine camera instead and the movement a long the rail is handled by this component not the sequencer.  First Test Once you configured your components save and compile your blueprint.\nDrag and drop your blueprint from the content browser into the scene. You should see a camera indicating the direction your ImageGenerator is going to record.\nStart the simulation and images should get generated in your projects Saved directory under UnrealGT.\nExamples You can find the Blueprint described in this Tutorial and additional examples in https://github.com/lolleko/UnrealGT/tree/master/Content/Examples.\nTo view the examples in the editor enable \u0026ldquo;Show Plugin Content\u0026rdquo; in the content browser\u0026rsquo;s view options.\nTo get familiar with the Plugin place the example actors in a map open the debug window as described in /basics/debugging-generation/ and write the examples name in the text box.\n"
},
{
	"uri": "https://unrealgt.github.io/components/generator/segmentation/",
	"title": "Segmentation",
	"tags": [],
	"description": "",
	"content": "GTSegmentationGeneratorComponent  \rCan generate segmentation for an image. You can assign components color by adding a filter color pair to the ComponentToColor map. Requires \u0026ldquo;Enabled with stencil\u0026rdquo; project setting in Engine \u0026gt; Rendering \u0026gt; Postprocessing \u0026gt; Custom-Depth Stencil Pass Will emit a JSON file containing the configured color mappings called \u0026ldquo;segmentation_info\u0026rdquo; in Saved/UnrealGT/{SessionName}/{Time}/{SegmentationGeneratorName} Note: Anti-Aliasing is disabled for segmentation generators by default!\rProperties\rImage\rEGTImageFileFormat  ImageFormat\rThe format the image will have, currently only .bmp and .png are supported.\r\rFIntPoint  Resolution\rThe resolution the generated images will have.\r\rbool  bRandomResolution\rIf enabled will choose a random resolution between Resolution and ResolutionMax for each captured image. This is useful for generating Training data.\r\rFIntPoint  ResolutionMax\rThe maximum Resolution to use if bRandomResolution is enabled.\r\rbool  bAntiAliasing\rPerform anti aliasing when an image is rendered. Highly recommended for basic images, but might cause issues if used with segmentation or depth generators. Temporal Anti-Aliasing might cause \u0026ldquo;jittering\u0026rdquo; if the generator is not moving.\r\rProjection\rfloat  FOVAngle\rCamera field of view (in degrees).\r\rSegmentation\rTMap\u0026lt;FGTObjectFilter, FColor\u0026gt;  ComponentToColor\rAssigns a segmentation color to the component/mesh if it matches the corresponding filter.\r\rbool  bShouldApplyCloseMorph\rThis can improve segmentation quality for partially translucent meshes (e.g. Fences, Foliage\u0026hellip;)\r\rbool  bColorEachComponentDifferent\r\rbool  bUseFilterForColorEachComponentDifferent\r\rFGTObjectFilter  ColorEachComponentDifferentFilter\r\r"
},
{
	"uri": "https://unrealgt.github.io/basics/debugging-generation/",
	"title": "Debugging Generation",
	"tags": [],
	"description": "",
	"content": "Click the UnrealGT Icon in the Toolbar to open the debug Window. Type the name of the generator component you want to debug into the text input to render debug info.\n "
},
{
	"uri": "https://unrealgt.github.io/components/trigger/",
	"title": "Trigger",
	"tags": [],
	"description": "",
	"content": "Chapter 2.3 Available Triggers \r"
},
{
	"uri": "https://unrealgt.github.io/components/generator/actorinfo/",
	"title": "ActorInfo",
	"tags": [],
	"description": "",
	"content": "GTActorInfoGeneratorComponent  \rGenerates information about actors in a scene (e.g. MeshName, BoundingBoxes, ActorName). The Output format can be customize via formatting strings.\rProperties\rOutput\rFString  FormatVector2DString\r\rFString  Format3DBoxString\r\rFString  Format2DBoxString\r\rFString  FormatRotatorString\r\rFString  FormatVector3DString\r\rbool  bAccurateBoundingBoxes\rDrastically Increase the accuracy of the bounding boxes, but requires an additional render pass. The additional render pass creates a segmentation map for the tracked actors and uses that map to refine the bounding boxes. Therefore Requires \u0026ldquo;Enabled with stencil\u0026rdquo; in Engine \u0026gt; Rendering \u0026gt; Postprocessing \u0026gt; Custom-Depth Stencil Pass to be set The additional render pass doubles the cost of creating the bounding boxes. The Larger the resolution of the LinkedGenerator the larger the performance hit.\r\rbool  bShouldApplyCloseMorph\rApply Close for Bounding Box Segmentation\r\rFGTGeneratorReference  LinkedImageGenerator\rLink an image generator to this component. The linked Generator is used to determine when an actor is \u0026ldquo;on screen\u0026rdquo; and should be tracked. Setting this is also required for generating 2D bounding boxes.\r\rFString  Header\r\rFString  FormatActorString\r\rFString  Separator\r\rFString  Footer\r\rTMap\u0026lt;FString, FString\u0026gt;  ReplaceStrings\r\rTracked\rfloat  MaxDistanceToCamera\r\rFVector2D  MinimalRequiredBoundingBoxSize\r\rbool  bOnlyTrackOnScreenActors\r\rbool  bOnlyTrackRecentlyRenderedActors\rTrack only actors that are \u0026ldquo;on screen\u0026rdquo;/\u0026ldquo;within an image\u0026rdquo;. This setting requires LinkedImageGenerator to be set.\r\rTArray\u0026lt;FGTObjectFilter\u0026gt;  TrackActorsThatMatchFilter\r\r"
},
{
	"uri": "https://unrealgt.github.io/components/generator/calibration/",
	"title": "Calibration",
	"tags": [],
	"description": "",
	"content": "GTCameraCalibrationComponent  \rCan bes used to get calibration parameters from image generators. Set CameraOneReference to retrieve data for one camera. Set CameraOneReference and CameraTwoReference to generate stereo calibration parameters.\rProperties\rCameras\rFGTGeneratorReference  CameraOneReference\r\rFGTGeneratorReference  CameraTwoReference\r\r"
},
{
	"uri": "https://unrealgt.github.io/",
	"title": "Unreal GT",
	"tags": [],
	"description": "",
	"content": "\rBy means of synthetic data generation, large amounts of image- and metadata can be extracted directly from a virtual scene, which in turn can be customized to meet the specific needs of the algorithm or the use-case. Furthermore, the use of virtual objects avoids problems that might arise due to data protec- tion issues and does not require the use of expensive sensors. We propose a framework for synthetic test data generation utilizing the Unreal Engine.\n Unreal EngineThe Unreal Engine provides a simulation environment that allows one to simulate complex situations in a virtual world, such as data acquisition with UAVs or autonomous diving.\n   Computer VisionBuilt-In Generators allow a large vareity of images to be synthesized. In addtion to basic color images, depth images, semantic segmenations, normal and depth maps. The Image Generators can also be used in conjungtion to create multi camera setups.\n    Deep LearningGenerate accurate grountruth, for machine learning tasks! Bounding boxes, pose data(WIP) and various other properties of scene objects can be extracted\n   Fast Setup \u0026amp; ConfigurationBy utilizing the UI of the Unreal Editor complex data generation constructs can be created in minutes, without touching a single line of code.\n  Click here to get started!\r\r--\r"
},
{
	"uri": "https://unrealgt.github.io/components/streamer/http/",
	"title": "Http",
	"tags": [],
	"description": "",
	"content": "GTHttpStreamerComponent  \rExample: https://github.com/unrealgt/unrealgt/tree/master/Examples/PythonHTTPClient\rProperties\r\rFGTGeneratorReference  GeneratorReference\r\rHttp\rFString  TargetUrl\r\rEGTHttpMethod  Method\r\rEGTHttpContentType  ContentType\r\r"
},
{
	"uri": "https://unrealgt.github.io/components/streamer/tcp/",
	"title": "Tcp",
	"tags": [],
	"description": "",
	"content": "GTSimpleTCPStreamer  \rExample: https://github.com/unrealgt/unrealgt/tree/master/Examples/PythonTCPClient\rProperties\r\rFGTGeneratorReference  GeneratorReference\r\rFString  IPAddress\r\ruint32  Port\r\r"
},
{
	"uri": "https://unrealgt.github.io/components/streamer/file/",
	"title": "File",
	"tags": [],
	"description": "",
	"content": "GTFileStreamerComponent  \rProperties\r\rFGTGeneratorReference  GeneratorReference\r\rFString  FileNameFormat\r\r"
},
{
	"uri": "https://unrealgt.github.io/advanced_examples/orb-slam2/",
	"title": "ORB-SLAM2",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://unrealgt.github.io/advanced_examples/yolo/",
	"title": "YOLO",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://unrealgt.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://unrealgt.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]